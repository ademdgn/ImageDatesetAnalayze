#!/usr/bin/env python3
"""
Ana Annotation Analiz ModÃ¼lÃ¼

Bu modÃ¼l tÃ¼m annotation analiz bileÅŸenlerini birleÅŸtiren ana sÄ±nÄ±fÄ± iÃ§erir.
"""

from typing import Dict, List, Optional, Any, Callable
from pathlib import Path

# Alt modÃ¼lleri import et
from .base_analyzer import BaseAnnotationAnalyzer
from .format_parsers import FormatParserFactory, parse_annotation_file
from .class_distribution import ClassDistributionAnalyzer
from .bbox_analyzer import BoundingBoxAnalyzer
from .quality_checker import AnnotationQualityChecker

class AnnotationAnalyzer(BaseAnnotationAnalyzer):
    """KapsamlÄ± annotation analizi yapan ana sÄ±nÄ±f"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        AnnotationAnalyzer sÄ±nÄ±fÄ±nÄ± baÅŸlat
        
        Args:
            config: Analiz konfigÃ¼rasyonu
        """
        super().__init__(config)
        
        # Alt bileÅŸenleri baÅŸlat
        self.class_analyzer = ClassDistributionAnalyzer(config)
        self.bbox_analyzer = BoundingBoxAnalyzer(config)
        self.quality_checker = AnnotationQualityChecker(config)
        
        # SonuÃ§ depolama
        self.analysis_results = {}
        self.annotation_data = []
        
    def load_annotations(self, annotation_path: str) -> Dict[str, Any]:
        """
        Tek annotation dosyasÄ±nÄ± yÃ¼kle
        
        Args:
            annotation_path: Annotation dosyasÄ± yolu
            
        Returns:
            Parse edilmiÅŸ annotation verisi
        """
        # Format'Ä± auto-detect et
        format_type = self.detect_annotation_format(annotation_path)
        
        if not format_type or format_type.startswith('unknown'):
            # VarsayÄ±lan olarak YOLO format'Ä±nÄ± dene
            format_type = 'yolo'
        
        # Parse et
        return parse_annotation_file(annotation_path, format_type, self.class_names)
    
    def analyze_dataset_annotations(self, annotation_paths: List[str],
                                  image_paths: List[str] = None,
                                  progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        TÃ¼m veri seti annotation'larÄ±nÄ± analiz et
        
        Args:
            annotation_paths: Annotation dosyasÄ± yollarÄ± listesi
            image_paths: GÃ¶rÃ¼ntÃ¼ dosyasÄ± yollarÄ± (opsiyonel)
            progress_callback: Ä°lerleme callback fonksiyonu
            
        Returns:
            KapsamlÄ± annotation analizi sonuÃ§larÄ±
        """
        print(f"ğŸ“ {len(annotation_paths)} annotation dosyasÄ± analiz ediliyor...")
        
        # Annotation dosyalarÄ±nÄ± yÃ¼kle
        annotation_data = []
        failed_files = []
        
        for i, ann_path in enumerate(annotation_paths):
            if progress_callback:
                progress_callback(i + 1, len(annotation_paths))
            else:
                self.progress_callback(i + 1, len(annotation_paths), "Annotation'lar yÃ¼kleniyor")
            
            parsed_data = self.load_annotations(ann_path)
            
            if parsed_data.get('parsing_failed', False):
                failed_files.append(parsed_data)
            else:
                annotation_data.append(parsed_data)
        
        print(f"\nâœ… {len(annotation_data)} annotation dosyasÄ± baÅŸarÄ±yla yÃ¼klendi")
        if failed_files:
            print(f"âŒ {len(failed_files)} dosya yÃ¼klenemedi")
        
        # Analiz sonuÃ§larÄ±nÄ± depola
        self.annotation_data = annotation_data
        
        # KapsamlÄ± analiz yap
        return self._perform_comprehensive_annotation_analysis(
            annotation_data, failed_files, image_paths
        )
    
    def _perform_comprehensive_annotation_analysis(self, annotation_data: List[Dict],
                                                 failed_files: List[Dict],
                                                 image_paths: List[str] = None) -> Dict[str, Any]:
        """
        KapsamlÄ± annotation analizi yap
        
        Args:
            annotation_data: BaÅŸarÄ±lÄ± parse edilmiÅŸ annotation verileri
            failed_files: BaÅŸarÄ±sÄ±z parse edilmiÅŸ dosyalar
            image_paths: GÃ¶rÃ¼ntÃ¼ dosyasÄ± yollarÄ±
            
        Returns:
            KapsamlÄ± analiz sonuÃ§larÄ±
        """
        print("ğŸ“Š Annotation istatistikleri hesaplanÄ±yor...")
        
        # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± analizi
        class_analysis = self.class_analyzer.analyze_class_distribution(annotation_data)
        
        print("ğŸ“ Bounding box analizi yapÄ±lÄ±yor...")
        
        # Bounding box analizi
        bbox_analysis = self.bbox_analyzer.analyze_bboxes(annotation_data)
        
        print("ğŸ” Kalite kontrolÃ¼ yapÄ±lÄ±yor...")
        
        # Kalite kontrolÃ¼
        quality_analysis = self.quality_checker.check_annotation_quality(
            annotation_data + failed_files, image_paths
        )
        
        print("ğŸ’¡ Ã–neriler oluÅŸturuluyor...")
        
        # Genel Ã¶neriler
        recommendations = self._generate_comprehensive_recommendations(
            class_analysis, bbox_analysis, quality_analysis
        )
        
        # Format analizi
        format_analysis = self._analyze_formats(annotation_data + failed_files)
        
        # SonuÃ§larÄ± birleÅŸtir
        results = {
            # Temel bilgiler
            'total_annotation_files': len(annotation_data) + len(failed_files),
            'successfully_parsed': len(annotation_data),
            'failed_to_parse': len(failed_files),
            'parse_success_rate': len(annotation_data) / (len(annotation_data) + len(failed_files)) * 100 
                                if (len(annotation_data) + len(failed_files)) > 0 else 0,
            
            # DetaylÄ± analizler
            'format_analysis': format_analysis,
            'class_analysis': class_analysis,
            'bbox_analysis': bbox_analysis,
            'quality_analysis': quality_analysis,
            
            # Ham veriler
            'annotation_data': annotation_data,
            'failed_files': failed_files,
            
            # Ã–neriler ve Ã¶zet
            'recommendations': recommendations,
            'analysis_summary': self._generate_analysis_summary(
                annotation_data, class_analysis, bbox_analysis, quality_analysis
            )
        }
        
        # SonuÃ§larÄ± depola
        self.analysis_results = results
        return results
    
    def _analyze_formats(self, all_annotation_data: List[Dict]) -> Dict[str, Any]:
        """Annotation formatlarÄ±nÄ± analiz et"""
        format_counts = {}
        total_files = len(all_annotation_data)
        
        for data in all_annotation_data:
            format_type = data.get('format', 'unknown')
            format_counts[format_type] = format_counts.get(format_type, 0) + 1
        
        # En yaygÄ±n format
        most_common_format = max(format_counts.items(), key=lambda x: x[1]) if format_counts else ('unknown', 0)
        
        # Format daÄŸÄ±lÄ±mÄ±
        format_distribution = []
        for fmt, count in format_counts.items():
            format_distribution.append({
                'format': fmt,
                'count': count,
                'percentage': (count / total_files) * 100 if total_files > 0 else 0
            })
        
        return {
            'total_files': total_files,
            'unique_formats': len(format_counts),
            'format_counts': format_counts,
            'format_distribution': format_distribution,
            'most_common_format': most_common_format[0],
            'most_common_count': most_common_format[1],
            'format_consistency': len(format_counts) == 1  # Tek format kullanÄ±lÄ±yor mu?
        }
    
    def _generate_comprehensive_recommendations(self, class_analysis: Dict,
                                              bbox_analysis: Dict,
                                              quality_analysis: Dict) -> List[str]:
        """KapsamlÄ± Ã¶neriler oluÅŸtur"""
        recommendations = []
        
        # SÄ±nÄ±f analizi Ã¶nerileri
        class_recommendations = class_analysis.get('recommendations', [])
        recommendations.extend(class_recommendations)
        
        # Bbox analizi Ã¶nerileri
        bbox_recommendations = bbox_analysis.get('recommendations', [])
        recommendations.extend(bbox_recommendations)
        
        # Kalite analizi Ã¶nerileri
        quality_recommendations = quality_analysis.get('recommendations', [])
        recommendations.extend(quality_recommendations)
        
        # Genel deÄŸerlendirme
        if not recommendations:
            recommendations.append("âœ¨ Annotation'lar genel olarak iyi durumda gÃ¶rÃ¼nÃ¼yor!")
        
        # Duplikasyon temizle ve sÄ±rala
        unique_recommendations = list(dict.fromkeys(recommendations))
        
        return unique_recommendations
    
    def _generate_analysis_summary(self, annotation_data: List[Dict],
                                 class_analysis: Dict, bbox_analysis: Dict,
                                 quality_analysis: Dict) -> Dict[str, Any]:
        """Analiz Ã¶zeti oluÅŸtur"""
        
        # Temel istatistikler
        total_annotations = sum(len(data.get('annotations', [])) for data in annotation_data)
        total_classes = class_analysis.get('total_classes', 0)
        
        # Kalite skorlarÄ±
        class_balance_score = self.class_analyzer.calculate_balance_score(
            class_analysis.get('class_counts', {})
        ) if hasattr(self.class_analyzer, 'calculate_balance_score') else 75
        
        bbox_quality_score = bbox_analysis.get('quality_assessment', {}).get('quality_score', 75)
        overall_quality_score = quality_analysis.get('overall_quality_score', 75)
        
        # Genel annotation skoru hesapla
        annotation_score = (class_balance_score * 0.3 + bbox_quality_score * 0.4 + overall_quality_score * 0.3)
        
        return {
            'total_annotation_files': len(annotation_data),
            'total_annotations': total_annotations,
            'total_classes': total_classes,
            'average_annotations_per_file': total_annotations / len(annotation_data) if annotation_data else 0,
            
            # Kalite skorlarÄ±
            'class_balance_score': round(class_balance_score, 2),
            'bbox_quality_score': round(bbox_quality_score, 2),
            'overall_quality_score': round(overall_quality_score, 2),
            'annotation_score': round(annotation_score, 2),
            'annotation_grade': self._grade_score(annotation_score),
            
            # Anahtar bulgular
            'key_findings': self._generate_key_findings(
                class_analysis, bbox_analysis, quality_analysis
            )
        }
    
    def _grade_score(self, score: float) -> str:
        """Skoru harf notuna dÃ¶nÃ¼ÅŸtÃ¼r"""
        if score >= 90:
            return 'A'
        elif score >= 80:
            return 'B'
        elif score >= 70:
            return 'C'
        elif score >= 60:
            return 'D'
        else:
            return 'F'
    
    def _generate_key_findings(self, class_analysis: Dict, bbox_analysis: Dict,
                             quality_analysis: Dict) -> List[str]:
        """Anahtar bulgular oluÅŸtur"""
        findings = []
        
        # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± bulgularÄ±
        total_classes = class_analysis.get('total_classes', 0)
        if total_classes > 0:
            imbalance_severity = class_analysis.get('imbalance_analysis', {}).get('imbalance_severity', 'unknown')
            if imbalance_severity == 'balanced':
                findings.append("âœ… SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± dengeli")
            elif imbalance_severity in ['moderate_imbalance', 'severe_imbalance']:
                findings.append("âš ï¸ SÄ±nÄ±f dengesizliÄŸi mevcut")
        
        # Bbox bulgularÄ±
        total_bboxes = bbox_analysis.get('total_bboxes', 0)
        if total_bboxes > 0:
            findings.append(f"ğŸ“¦ {total_bboxes} bounding box analiz edildi")
        
        # Kalite bulgularÄ±
        overall_quality = quality_analysis.get('overall_quality_score', 0)
        if overall_quality >= 85:
            findings.append("ğŸ† YÃ¼ksek annotation kalitesi")
        elif overall_quality < 70:
            findings.append("ğŸ”§ Annotation kalitesi iyileÅŸtirilebilir")
        
        # Format bulgularÄ±
        if len(self.analysis_results.get('format_analysis', {}).get('format_counts', {})) > 1:
            findings.append("ğŸ”„ Ã‡oklu annotation formatÄ± kullanÄ±lÄ±yor")
        
        return findings
    
    def get_annotation_summary_text(self) -> str:
        """Annotation analiz Ã¶zetini metin olarak al"""
        if not self.analysis_results:
            return "HenÃ¼z annotation analizi yapÄ±lmadÄ±."
        
        summary = self.analysis_results.get('analysis_summary', {})
        
        text = f"""
ğŸ“ ANNOTATION ANALÄ°Z Ã–ZETÄ°
{'='*50}

ğŸ“Š Temel Bilgiler:
â€¢ Toplam annotation dosyasÄ±: {summary.get('total_annotation_files', 0)}
â€¢ Toplam annotation: {summary.get('total_annotations', 0)}
â€¢ Toplam sÄ±nÄ±f sayÄ±sÄ±: {summary.get('total_classes', 0)}
â€¢ Dosya baÅŸÄ±na ortalama annotation: {summary.get('average_annotations_per_file', 0):.1f}

ğŸ¯ Kalite SkorlarÄ±:
â€¢ SÄ±nÄ±f dengesi: {summary.get('class_balance_score', 0)}/100
â€¢ Bbox kalitesi: {summary.get('bbox_quality_score', 0)}/100
â€¢ Genel kalite: {summary.get('overall_quality_score', 0)}/100
â€¢ Annotation skoru: {summary.get('annotation_score', 0)}/100 (Not: {summary.get('annotation_grade', 'F')})

ğŸ’¡ Anahtar Bulgular:
"""
        
        for finding in summary.get('key_findings', []):
            text += f"â€¢ {finding}\n"
        
        text += f"\nğŸ”§ Ã–neriler:\n"
        for recommendation in self.analysis_results.get('recommendations', [])[:5]:  # Ä°lk 5 Ã¶neri
            text += f"â€¢ {recommendation}\n"
        
        return text
    
    def save_annotation_results(self, output_path: str) -> bool:
        """
        Annotation analiz sonuÃ§larÄ±nÄ± JSON dosyasÄ±na kaydet
        
        Args:
            output_path: Ã‡Ä±ktÄ± dosyasÄ± yolu
            
        Returns:
            BaÅŸarÄ± durumu
        """
        try:
            import json
            
            # Ã‡Ä±ktÄ± dizinini oluÅŸtur
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            
            # NumPy array'leri listlere dÃ¶nÃ¼ÅŸtÃ¼r
            results_copy = self._prepare_results_for_json(self.analysis_results)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results_copy, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… Annotation analiz sonuÃ§larÄ± kaydedildi: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ SonuÃ§lar kaydedilirken hata: {e}")
            return False
    
    def _prepare_results_for_json(self, data: Any) -> Any:
        """JSON serileÅŸtirme iÃ§in veriyi hazÄ±rla"""
        import numpy as np
        
        if isinstance(data, dict):
            return {key: self._prepare_results_for_json(value) for key, value in data.items()}
        elif isinstance(data, list):
            return [self._prepare_results_for_json(item) for item in data]
        elif isinstance(data, np.ndarray):
            return data.tolist()
        elif isinstance(data, (np.int64, np.int32)):
            return int(data)
        elif isinstance(data, (np.float64, np.float32)):
            return float(data)
        else:
            return data
    
    def find_annotation_files_in_dataset(self, dataset_path: str, 
                                       annotation_format: str = 'auto') -> List[str]:
        """
        Dataset dizinindeki annotation dosyalarÄ±nÄ± bul
        
        Args:
            dataset_path: Dataset ana dizini
            annotation_format: Annotation formatÄ±
            
        Returns:
            Bulunan annotation dosyalarÄ± listesi
        """
        return self.find_annotation_files(dataset_path, annotation_format)
    
    def quick_annotation_analysis(self, annotation_paths: List[str], 
                                sample_size: int = 50) -> Dict[str, Any]:
        """
        HÄ±zlÄ± annotation analizi yap
        
        Args:
            annotation_paths: TÃ¼m annotation yollarÄ±
            sample_size: Analiz edilecek Ã¶rnek boyutu
            
        Returns:
            HÄ±zlÄ± analiz sonuÃ§larÄ±
        """
        import random
        
        # Rastgele Ã¶rnek seÃ§
        if len(annotation_paths) <= sample_size:
            sample_paths = annotation_paths
        else:
            sample_paths = random.sample(annotation_paths, sample_size)
        
        print(f"ğŸš€ HÄ±zlÄ± annotation analizi: {len(sample_paths)} dosya Ã¶rneÄŸi")
        
        # Analiz yap
        results = self.analyze_dataset_annotations(sample_paths)
        
        # Ã–rnek analizi olduÄŸunu belirt
        results['is_sample_analysis'] = True
        results['sample_size'] = len(sample_paths)
        results['total_available'] = len(annotation_paths)
        results['sample_ratio'] = len(sample_paths) / len(annotation_paths)
        
        return results
